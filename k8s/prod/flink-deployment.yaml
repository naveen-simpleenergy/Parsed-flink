apiVersion: flink.apache.org/v1beta1
kind: FlinkDeployment
metadata:
  name: can-parser-job-prod
  namespace: flink-prod
spec:
  serviceAccount: flink-prod
  mode: native
  image: 534375227638.dkr.ecr.ap-south-1.amazonaws.com/se-prod-flink-can-parser:v1.0.11
  flinkVersion: v1_20
  logConfiguration:
    log4j-console.properties: |+
      # Override only the console layout pattern
      # appender.console.layout.pattern = %d{yyyy-MM-dd HH:mm:ss,SSS} %-5p - %m%n
      # This affects logging for both user code and Flink
      rootLogger.level = INFO
      rootLogger.appenderRef.console.ref = ConsoleAppender
      rootLogger.appenderRef.rolling.ref = RollingFileAppender

      # Uncomment this if you want to _only_ change Flink's logging
      #logger.flink.name = org.apache.flink
      #logger.flink.level = INFO

      # The following lines keep the log level of common libraries/connectors on
      # log level INFO. The root logger does not override this. You have to manually
      # change the log levels here.
      logger.akka.name = akka
      logger.akka.level = INFO
      logger.kafka.name= org.apache.kafka
      logger.kafka.level = INFO
      logger.hadoop.name = org.apache.hadoop
      logger.hadoop.level = INFO
      logger.zookeeper.name = org.apache.zookeeper
      logger.zookeeper.level = INFO

      # Log all infos to the console
      appender.console.name = ConsoleAppender
      appender.console.type = CONSOLE
      appender.console.layout.type = PatternLayout
      appender.console.layout.pattern = %d{yyyy-MM-dd HH:mm:ss,SSS}{Asia/Kolkata} %-5p - %m%n

      # Log all infos in the given rolling file
      appender.rolling.name = RollingFileAppender
      appender.rolling.type = RollingFile
      appender.rolling.append = false
      appender.rolling.fileName = ${sys:log.file}
      appender.rolling.filePattern = ${sys:log.file}.%i
      appender.rolling.layout.type = PatternLayout
      appender.rolling.layout.pattern = %d{yyyy-MM-dd HH:mm:ss,SSS}{Asia/Kolkata} %-5p - %m%n
      appender.rolling.policies.type = Policies
      appender.rolling.policies.size.type = SizeBasedTriggeringPolicy
      appender.rolling.policies.size.size=100MB
      appender.rolling.strategy.type = DefaultRolloverStrategy
      appender.rolling.strategy.max = 10

      # Suppress the irrelevant (wrong) warnings from the Netty channel handler
      logger.netty.name = org.apache.flink.shaded.akka.org.jboss.netty.channel.DefaultChannelPipeline
      logger.netty.level = OFF

      # The monitor interval in seconds to enable log4j automatic reconfiguration
      # monitorInterval = 30
      # Flink Deployment Logging Overrides
      # rootLogger.level = DEBUG

  flinkConfiguration:
    taskmanager.numberOfTaskSlots: "10"
    # execution.checkpointing.interval: "30s"
    # execution.checkpointing.timeout: "10min"
    # execution.checkpointing.mode: EXACTLY_ONCE
    state.checkpoints.dir: "s3://eks-flink-prod-bucket/parsed-checkpoints"
    state.savepoints.dir: "s3://eks-flink-prod-bucket/savepoints"
    pipeline.jars: local:///opt/flink/lib/flink-connector-kafka-3.4.0-1.20.jar
    # pipeline.classpaths: "local:///opt/flink/lib/flink-connector-kafka-1.17.2.jar"
  podTemplate:
    # spec:
    #   nodeSelector:
    #     eks.amazonaws.com/nodegroup: flink-ng
    
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: app
                operator: In
                values:
                - telemetry-ng

    # spec:
    #   nodeSelector:
    #     eks.amazonaws.com/nodegroup: flink-ng
      # tolerations:
      #   - key: "flink-node"
      #     operator: "Exists"
      #     # value: "true"
      #     effect: "NoSchedule"

  jobManager:
    resource:
      memory: "6144m"
      cpu: 1
  taskManager:
    resource:
      memory: "3584m"
      cpu: 1
  job:
    jarURI: local:///opt/flink/lib/flink-connector-kafka-3.4.0-1.20.jar  # Dummy JAR, required for FlinkDeployment
    args: ["-py", "/opt/pyflink-job/main.py", "--pyFiles", "dependencies.zip"]
    # args:
    #   - "--pyExecutable"
    #   - "/usr/bin/python3"  
    #   - "--pyfs"
    #   - "local:///opt/pyflink-job/dependencies.zip"  
    #   - "--py"
    #   - "/opt/pyflink-job/main.py"
    parallelism: 20
    state: running

 