apiVersion: v1
data:
  flink-conf.yaml: |
    execution.checkpointing.mode: EXACTLY_ONCE
    execution.checkpointing.interval: 30s
    execution.checkpointing.timeout: 10min
    state.checkpoints.dir: s3://eks-flink-bucket/checkpoints
    state.savepoints.dir: s3://eks-flink-bucket/savepoints
    kubernetes.config.maps: flink-config
    pipeline.jars: local:///opt/flink/lib/flink-connector-kafka-3.3.0-1.20.jar
    ################################################################################
    #  Licensed to the Apache Software Foundation (ASF) under one
    #  or more contributor license agreements.  See the NOTICE file
    #  distributed with this work for additional information
    #  regarding copyright ownership.  The ASF licenses this file
    #  to you under the Apache License, Version 2.0 (the
    #  "License"); you may not use this file except in compliance
    #  with the License.  You may obtain a copy of the License at
    #
    #      http://www.apache.org/licenses/LICENSE-2.0
    #
    #  Unless required by applicable law or agreed to in writing, software
    #  distributed under the License is distributed on an "AS IS" BASIS,
    #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    #  See the License for the specific language governing permissions and
    # limitations under the License.
    ################################################################################

    # Flink job/cluster related configs
    taskmanager.numberOfTaskSlots: 1
    parallelism.default: 1

    # These parameters are required for Java 17 support.
    # These should be kept in-sync with the flink dist env.java.opts.all defaults (for the given flink version) in: flink-dist/src/main/resources/config.yaml
    # Flink 1.18 uses env.java.opts.all, if a user supplies their own version of these opts in their FlinkDeployment the options below will be overridden.
    # env.java.default-opts.all is used for 1.19 onwards so users can supply their own opts.all in their Job deployments and have these appended.
    kubernetes.operator.default-configuration.flink-version.v1_18.env.java.opts.all: --add-exports=java.base/sun.net.util=ALL-UNNAMED --add-exports=java.rmi/sun.rmi.registry=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.api=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.file=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.parser=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-exports=java.security.jgss/sun.security.krb5=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.time=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.locks=ALL-UNNAMED
    kubernetes.operator.default-configuration.flink-version.v1_19+.env.java.default-opts.all: --add-exports=java.base/sun.net.util=ALL-UNNAMED --add-exports=java.rmi/sun.rmi.registry=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.api=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.file=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.parser=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-exports=java.security.jgss/sun.security.krb5=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.time=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.locks=ALL-UNNAMED

    # Flink operator related configs
    # kubernetes.operator.reconcile.interval: 60 s
    # kubernetes.operator.reconcile.parallelism: 5
    # kubernetes.operator.flink.client.cancel.timeout: 1 min
    # kubernetes.operator.resource.cleanup.timeout: 60 s
    # kubernetes.operator.observer.rest-ready.delay: 10 s
    # kubernetes.operator.observer.progress-check.interval: 10 s
    # kubernetes.operator.observer.savepoint.trigger.grace-period: 10 s
    # kubernetes.operator.flink.client.timeout: 10 s
    # kubernetes.operator.deployment.rollback.enabled: false
    # kubernetes.operator.deployment.readiness.timeout: 5min
    # kubernetes.operator.user.artifacts.base.dir: /opt/flink/artifacts
    # kubernetes.operator.job.upgrade.ignore-pending-savepoint: false
    # kubernetes.operator.watched.namespaces: ns1,ns2
    # kubernetes.operator.label.selector: flink=enabled
    # kubernetes.operator.dynamic.namespaces.enabled: false
    # kubernetes.operator.retry.initial.interval: 5 s
    # kubernetes.operator.retry.interval.multiplier: 2
    # kubernetes.operator.retry.max.attempts: 10
    # kubernetes.operator.exception.stacktrace.enabled: false
    # kubernetes.operator.exception.stacktrace.max.length: 2048
    # kubernetes.operator.exception.field.max.length: 2048
    # kubernetes.operator.exception.throwable.list.max.count: 2
    # kubernetes.operator.exception.label.mapper: Job has already been submitted:duplicatedJobFound,Server returned HTTP response code:httpResponseCodeFound
    # kubernetes.operator.leader-election.enabled: false
    # kubernetes.operator.leader-election.lease-name: flink-operator-lease

    # kubernetes.operator.snapshot.resource.enabled: true
    # kubernetes.operator.savepoint.dispose-on-delete: true

    # kubernetes.operator.metrics.reporter.slf4j.factory.class: org.apache.flink.metrics.slf4j.Slf4jReporterFactory
    # kubernetes.operator.metrics.reporter.slf4j.interval: 5 MINUTE

    # Flink Config Overrides
    kubernetes.operator.metrics.reporter.slf4j.factory.class: org.apache.flink.metrics.slf4j.Slf4jReporterFactory
    kubernetes.operator.metrics.reporter.slf4j.interval: 5 MINUTE

    kubernetes.operator.reconcile.interval: 15 s
    kubernetes.operator.observer.progress-check.interval: 5 s

    kubernetes.operator.health.probe.enabled: true
    kubernetes.operator.health.probe.port: 8085
  log4j-console.properties: |
    ################################################################################
    #  Licensed to the Apache Software Foundation (ASF) under one
    #  or more contributor license agreements.  See the NOTICE file
    #  distributed with this work for additional information
    #  regarding copyright ownership.  The ASF licenses this file
    #  to you under the Apache License, Version 2.0 (the
    #  "License"); you may not use this file except in compliance
    #  with the License.  You may obtain a copy of the License at
    #
    #      http://www.apache.org/licenses/LICENSE-2.0
    #
    #  Unless required by applicable law or agreed to in writing, software
    #  distributed under the License is distributed on an "AS IS" BASIS,
    #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    #  See the License for the specific language governing permissions and
    # limitations under the License.
    ################################################################################

    # This affects logging for both user code and Flink
    rootLogger.level = INFO
    rootLogger.appenderRef.console.ref = ConsoleAppender
    rootLogger.appenderRef.rolling.ref = RollingFileAppender

    # Uncomment this if you want to _only_ change Flink's logging
    #logger.flink.name = org.apache.flink
    #logger.flink.level = INFO

    # The following lines keep the log level of common libraries/connectors on
    # log level INFO. The root logger does not override this. You have to manually
    # change the log levels here.
    logger.akka.name = akka
    logger.akka.level = INFO
    logger.kafka.name= org.apache.kafka
    logger.kafka.level = INFO
    logger.hadoop.name = org.apache.hadoop
    logger.hadoop.level = INFO
    logger.zookeeper.name = org.apache.zookeeper
    logger.zookeeper.level = INFO

    # Log all infos to the console
    appender.console.name = ConsoleAppender
    appender.console.type = CONSOLE
    appender.console.layout.type = PatternLayout
    appender.console.layout.pattern = %d{yyyy-MM-dd HH:mm:ss,SSS} %-5p %-60c %x - %m%n

    # Log all infos in the given rolling file
    appender.rolling.name = RollingFileAppender
    appender.rolling.type = RollingFile
    appender.rolling.append = false
    appender.rolling.fileName = ${sys:log.file}
    appender.rolling.filePattern = ${sys:log.file}.%i
    appender.rolling.layout.type = PatternLayout
    appender.rolling.layout.pattern = %d{yyyy-MM-dd HH:mm:ss,SSS} %-5p %-60c %x - %m%n
    appender.rolling.policies.type = Policies
    appender.rolling.policies.size.type = SizeBasedTriggeringPolicy
    appender.rolling.policies.size.size=100MB
    appender.rolling.strategy.type = DefaultRolloverStrategy
    appender.rolling.strategy.max = 10

    # Suppress the irrelevant (wrong) warnings from the Netty channel handler
    logger.netty.name = org.apache.flink.shaded.akka.org.jboss.netty.channel.DefaultChannelPipeline
    logger.netty.level = OFF

    # The monitor interval in seconds to enable log4j automatic reconfiguration
    # monitorInterval = 30
    # Flink Deployment Logging Overrides
    # rootLogger.level = DEBUG
  log4j-operator.properties: |+
    ################################################################################
    #  Licensed to the Apache Software Foundation (ASF) under one
    #  or more contributor license agreements.  See the NOTICE file
    #  distributed with this work for additional information
    #  regarding copyright ownership.  The ASF licenses this file
    #  to you under the Apache License, Version 2.0 (the
    #  "License"); you may not use this file except in compliance
    #  with the License.  You may obtain a copy of the License at
    #
    #      http://www.apache.org/licenses/LICENSE-2.0
    #
    #  Unless required by applicable law or agreed to in writing, software
    #  distributed under the License is distributed on an "AS IS" BASIS,
    #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    #  See the License for the specific language governing permissions and
    # limitations under the License.
    ################################################################################

    rootLogger.level = INFO
    rootLogger.appenderRef.console.ref = ConsoleAppender

    # Log all infos to the console
    appender.console.name = ConsoleAppender
    appender.console.type = CONSOLE
    appender.console.layout.type = PatternLayout
    appender.console.layout.pattern = %style{%d}{yellow} %style{%-30c{1.}}{cyan} %highlight{[%-5level]%notEmpty{[%X{resource.namespace}/}%notEmpty{%X{resource.name}]} %msg%n%throwable}

    # Do not log config loading
    logger.conf.name = org.apache.flink.configuration.GlobalConfiguration
    logger.conf.level = ERROR

    # Avoid logging fallback key INFO messages
    logger.conf.name = org.apache.flink.configuration.Configuration
    logger.conf.level = ERROR

    # The monitor interval in seconds to enable log4j automatic reconfiguration
    # monitorInterval = 30
    # Flink Operator Logging Overrides
    # rootLogger.level = DEBUG
    # logger.operator.name= org.apache.flink.kubernetes.operator
    # logger.operator.level = DEBUG

kind: ConfigMap
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"v1","data":{"flink-conf.yaml":"execution.checkpointing.mode: EXACTLY_ONCE\nexecution.checkpointing.interval: 30s\nexecution.checkpointing.timeout: 10min\nstate.checkpoints.dir: s3://eks-flink-bucket/checkpoints\nstate.savepoints.dir: s3://eks-flink-bucket/savepoints\nkubernetes.config.maps: flink-config\npipeline.jars: \"local:///opt/flink/lib/flink-connector-kafka-1.17.2.jar\"\n################################################################################\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  \"License\"); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing, software\n#  distributed under the License is distributed on an \"AS IS\" BASIS,\n#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#  See the License for the specific language governing permissions and\n# limitations under the License.\n################################################################################\n\n# Flink job/cluster related configs\ntaskmanager.numberOfTaskSlots: 1\nparallelism.default: 1\n\n# These parameters are required for Java 17 support.\n# These should be kept in-sync with the flink dist env.java.opts.all defaults (for the given flink version) in: flink-dist/src/main/resources/config.yaml\n# Flink 1.18 uses env.java.opts.all, if a user supplies their own version of these opts in their FlinkDeployment the options below will be overridden.\n# env.java.default-opts.all is used for 1.19 onwards so users can supply their own opts.all in their Job deployments and have these appended.\nkubernetes.operator.default-configuration.flink-version.v1_18.env.java.opts.all: --add-exports=java.base/sun.net.util=ALL-UNNAMED --add-exports=java.rmi/sun.rmi.registry=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.api=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.file=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.parser=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-exports=java.security.jgss/sun.security.krb5=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.time=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.locks=ALL-UNNAMED\nkubernetes.operator.default-configuration.flink-version.v1_19+.env.java.default-opts.all: --add-exports=java.base/sun.net.util=ALL-UNNAMED --add-exports=java.rmi/sun.rmi.registry=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.api=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.file=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.parser=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-exports=java.security.jgss/sun.security.krb5=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.time=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.locks=ALL-UNNAMED\n\n# Flink operator related configs\n# kubernetes.operator.reconcile.interval: 60 s\n# kubernetes.operator.reconcile.parallelism: 5\n# kubernetes.operator.flink.client.cancel.timeout: 1 min\n# kubernetes.operator.resource.cleanup.timeout: 60 s\n# kubernetes.operator.observer.rest-ready.delay: 10 s\n# kubernetes.operator.observer.progress-check.interval: 10 s\n# kubernetes.operator.observer.savepoint.trigger.grace-period: 10 s\n# kubernetes.operator.flink.client.timeout: 10 s\n# kubernetes.operator.deployment.rollback.enabled: false\n# kubernetes.operator.deployment.readiness.timeout: 5min\n# kubernetes.operator.user.artifacts.base.dir: /opt/flink/artifacts\n# kubernetes.operator.job.upgrade.ignore-pending-savepoint: false\n# kubernetes.operator.watched.namespaces: ns1,ns2\n# kubernetes.operator.label.selector: flink=enabled\n# kubernetes.operator.dynamic.namespaces.enabled: false\n# kubernetes.operator.retry.initial.interval: 5 s\n# kubernetes.operator.retry.interval.multiplier: 2\n# kubernetes.operator.retry.max.attempts: 10\n# kubernetes.operator.exception.stacktrace.enabled: false\n# kubernetes.operator.exception.stacktrace.max.length: 2048\n# kubernetes.operator.exception.field.max.length: 2048\n# kubernetes.operator.exception.throwable.list.max.count: 2\n# kubernetes.operator.exception.label.mapper: Job has already been submitted:duplicatedJobFound,Server returned HTTP response code:httpResponseCodeFound\n# kubernetes.operator.leader-election.enabled: false\n# kubernetes.operator.leader-election.lease-name: flink-operator-lease\n\n# kubernetes.operator.snapshot.resource.enabled: true\n# kubernetes.operator.savepoint.dispose-on-delete: true\n\n# kubernetes.operator.metrics.reporter.slf4j.factory.class: org.apache.flink.metrics.slf4j.Slf4jReporterFactory\n# kubernetes.operator.metrics.reporter.slf4j.interval: 5 MINUTE\n\n# Flink Config Overrides\nkubernetes.operator.metrics.reporter.slf4j.factory.class: org.apache.flink.metrics.slf4j.Slf4jReporterFactory\nkubernetes.operator.metrics.reporter.slf4j.interval: 5 MINUTE\n\nkubernetes.operator.reconcile.interval: 15 s\nkubernetes.operator.observer.progress-check.interval: 5 s\n\nkubernetes.operator.health.probe.enabled: true\nkubernetes.operator.health.probe.port: 8085\n","log4j-console.properties":"################################################################################\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  \"License\"); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing, software\n#  distributed under the License is distributed on an \"AS IS\" BASIS,\n#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#  See the License for the specific language governing permissions and\n# limitations under the License.\n################################################################################\n\n# This affects logging for both user code and Flink\nrootLogger.level = INFO\nrootLogger.appenderRef.console.ref = ConsoleAppender\nrootLogger.appenderRef.rolling.ref = RollingFileAppender\n\n# Uncomment this if you want to _only_ change Flink's logging\n#logger.flink.name = org.apache.flink\n#logger.flink.level = INFO\n\n# The following lines keep the log level of common libraries/connectors on\n# log level INFO. The root logger does not override this. You have to manually\n# change the log levels here.\nlogger.akka.name = akka\nlogger.akka.level = INFO\nlogger.kafka.name= org.apache.kafka\nlogger.kafka.level = INFO\nlogger.hadoop.name = org.apache.hadoop\nlogger.hadoop.level = INFO\nlogger.zookeeper.name = org.apache.zookeeper\nlogger.zookeeper.level = INFO\n\n# Log all infos to the console\nappender.console.name = ConsoleAppender\nappender.console.type = CONSOLE\nappender.console.layout.type = PatternLayout\nappender.console.layout.pattern = %d{yyyy-MM-dd HH:mm:ss,SSS} %-5p %-60c %x - %m%n\n\n# Log all infos in the given rolling file\nappender.rolling.name = RollingFileAppender\nappender.rolling.type = RollingFile\nappender.rolling.append = false\nappender.rolling.fileName = ${sys:log.file}\nappender.rolling.filePattern = ${sys:log.file}.%i\nappender.rolling.layout.type = PatternLayout\nappender.rolling.layout.pattern = %d{yyyy-MM-dd HH:mm:ss,SSS} %-5p %-60c %x - %m%n\nappender.rolling.policies.type = Policies\nappender.rolling.policies.size.type = SizeBasedTriggeringPolicy\nappender.rolling.policies.size.size=100MB\nappender.rolling.strategy.type = DefaultRolloverStrategy\nappender.rolling.strategy.max = 10\n\n# Suppress the irrelevant (wrong) warnings from the Netty channel handler\nlogger.netty.name = org.apache.flink.shaded.akka.org.jboss.netty.channel.DefaultChannelPipeline\nlogger.netty.level = OFF\n\n# The monitor interval in seconds to enable log4j automatic reconfiguration\n# monitorInterval = 30\n# Flink Deployment Logging Overrides\n# rootLogger.level = DEBUG\n","log4j-operator.properties":"################################################################################\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  \"License\"); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing, software\n#  distributed under the License is distributed on an \"AS IS\" BASIS,\n#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#  See the License for the specific language governing permissions and\n# limitations under the License.\n################################################################################\n\nrootLogger.level = INFO\nrootLogger.appenderRef.console.ref = ConsoleAppender\n\n# Log all infos to the console\nappender.console.name = ConsoleAppender\nappender.console.type = CONSOLE\nappender.console.layout.type = PatternLayout\nappender.console.layout.pattern = %style{%d}{yellow} %style{%-30c{1.}}{cyan} %highlight{[%-5level]%notEmpty{[%X{resource.namespace}/}%notEmpty{%X{resource.name}]} %msg%n%throwable}\n\n# Do not log config loading\nlogger.conf.name = org.apache.flink.configuration.GlobalConfiguration\nlogger.conf.level = ERROR\n\n# Avoid logging fallback key INFO messages\nlogger.conf.name = org.apache.flink.configuration.Configuration\nlogger.conf.level = ERROR\n\n# The monitor interval in seconds to enable log4j automatic reconfiguration\n# monitorInterval = 30\n# Flink Operator Logging Overrides\n# rootLogger.level = DEBUG\n# logger.operator.name= org.apache.flink.kubernetes.operator\n# logger.operator.level = DEBUG\n\n"},"kind":"ConfigMap","metadata":{"annotations":{"meta.helm.sh/release-name":"flink-kubernetes-operator","meta.helm.sh/release-namespace":"flink-stage"},"creationTimestamp":"2025-03-20T22:10:46Z","labels":{"app.kubernetes.io/managed-by":"Helm","app.kubernetes.io/name":"flink-kubernetes-operator","app.kubernetes.io/version":"1.11.0","helm.sh/chart":"flink-kubernetes-operator-1.11.0"},"name":"flink-operator-config","namespace":"flink-stage","resourceVersion":"48252920","uid":"756ff62b-72ad-45ee-bad7-37f480c8f199"}}
    meta.helm.sh/release-name: flink-kubernetes-operator
    meta.helm.sh/release-namespace: flink-stage
  labels:
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: flink-kubernetes-operator
    app.kubernetes.io/version: 1.11.0
    helm.sh/chart: flink-kubernetes-operator-1.11.0
  name: flink-operator-config
  namespace: flink-stage
